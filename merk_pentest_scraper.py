import time
import csv
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException, TimeoutException
import random

class MerkPentestScraper:
    def __init__(self):
        self.setup_driver()
        self.companies = []
        self.page_count = 0
        
    def setup_driver(self):
        """Setup Chrome driver with anti-detection measures for testing"""
        chrome_options = Options()
        
        # Anti-detection headers for penetration testing
        chrome_options.add_argument("--disable-blink-features=AutomationControlled")
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-gpu")
        
        # Realistic user agent
        chrome_options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
        
        self.driver = webdriver.Chrome(options=chrome_options)
        self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        
    def manual_login(self):
        """Navigate to merk.cz and wait for manual login and filtering"""
        print("=" * 60)
        print("PENETRAČNÍ TEST - MERK.CZ SCRAPING")
        print("=" * 60)
        print("\n1. Navigating to merk.cz...")
        self.driver.get("https://www.merk.cz")
        
        print("\n2. PROSÍM PROVEĎTE NÁSLEDUJÍCÍ KROKY:")
        print("   - Přihlaste se do systému")
        print("   - Nastavte požadované filtry pro vyhledávání")
        print("   - Počkejte až se zobrazí tabulka s výsledky")
        print("\n3. Po dokončení stiskněte ENTER v tomto terminálu...")
        input()
        print("\n4. Zahajuji scraping...")
        
    def extract_companies_from_page(self):
        """Extract company names from current page table"""
        companies_on_page = []
        
        try:
            # Wait for table to be present
            wait = WebDriverWait(self.driver, 10)
            table = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table.large")))
            
            # Find all company links in the table
            company_links = self.driver.find_elements(By.CSS_SELECTOR, "table.large tbody tr td:first-child a")
            
            for link in company_links:
                company_name = link.text.strip()
                if company_name:
                    companies_on_page.append(company_name)
                    print(f"   Nalezena firma: {company_name}")
            
            return companies_on_page
            
        except TimeoutException:
            print("   [CHYBA] Tabulka nebyla nalezena na stránce")
            return []
        except Exception as e:
            print(f"   [CHYBA] Při extrakci dat: {str(e)}")
            return []
    
    def click_next_page(self):
        """Click on next page button"""
        try:
            # Look for "Další" button
            next_buttons = self.driver.find_elements(By.XPATH, "//button[contains(text(), 'Další')]")
            
            if not next_buttons:
                # Alternative: look for button with name="page_num"
                next_buttons = self.driver.find_elements(By.CSS_SELECTOR, "button[name='page_num']")
            
            if next_buttons:
                # Find the correct next button (usually the last one)
                for button in reversed(next_buttons):
                    if button.is_enabled() and button.is_displayed():
                        # Scroll to button
                        self.driver.execute_script("arguments[0].scrollIntoView(true);", button)
                        time.sleep(0.5)
                        
                        # Click using JavaScript to avoid interception
                        self.driver.execute_script("arguments[0].click();", button)
                        return True
            
            print("   [INFO] Tlačítko 'Další' nenalezeno - pravděpodobně poslední stránka")
            return False
            
        except Exception as e:
            print(f"   [CHYBA] Při přechodu na další stránku: {str(e)}")
            return False
    
    def add_human_delay(self):
        """Add random delay to simulate human behavior"""
        delay = random.uniform(2, 5)  # Random delay between 2-5 seconds
        time.sleep(delay)
    
    def save_results(self):
        """Save companies to CSV file"""
        filename = f"merk_companies_{time.strftime('%Y%m%d_%H%M%S')}.csv"
        
        with open(filename, 'w', newline='', encoding='utf-8') as file:
            writer = csv.writer(file)
            writer.writerow(['Název firmy'])
            
            for company in self.companies:
                writer.writerow([company])
        
        print(f"\nVýsledky uloženy do: {filename}")
        return filename
    
    def run_scraping(self):
        """Main scraping loop"""
        self.manual_login()
        
        try:
            while True:
                self.page_count += 1
                print(f"\n[STRÁNKA {self.page_count}]")
                
                # Extract companies from current page
                page_companies = self.extract_companies_from_page()
                
                if page_companies:
                    self.companies.extend(page_companies)
                    print(f"   Nalezeno {len(page_companies)} firem na této stránce")
                    print(f"   Celkem zpracováno: {len(self.companies)} firem")
                else:
                    print("   Žádné firmy nenalezeny na této stránce")
                
                # Add human-like delay
                self.add_human_delay()
                
                # Try to go to next page
                if not self.click_next_page():
                    print("\n[KONEC] Dosažena poslední stránka")
                    break
                
                # Wait for page to load
                print("   Čekám na načtení další stránky...")
                time.sleep(3)
                
                # Optional: Save intermediate results every 10 pages
                if self.page_count % 10 == 0:
                    temp_filename = f"merk_companies_temp_page{self.page_count}.csv"
                    with open(temp_filename, 'w', newline='', encoding='utf-8') as file:
                        writer = csv.writer(file)
                        writer.writerow(['Název firmy'])
                        for company in self.companies:
                            writer.writerow([company])
                    print(f"   [BACKUP] Průběžné výsledky uloženy: {temp_filename}")
        
        except KeyboardInterrupt:
            print("\n[PŘERUŠENO] Scraping ukončen uživatelem")
        
        except Exception as e:
            print(f"\n[KRITICKÁ CHYBA] {str(e)}")
        
        finally:
            # Save final results
            if self.companies:
                filename = self.save_results()
                print(f"\nCELKOVÉ STATISTIKY:")
                print(f"  - Zpracováno stránek: {self.page_count}")
                print(f"  - Nalezeno firem: {len(self.companies)}")
                print(f"  - Výsledky uloženy do: {filename}")
            else:
                print("\nŽádná data nebyla extrahována")
            
            # Close browser
            print("\nZavírám prohlížeč...")
            self.driver.quit()

def main():
    print("MERK.CZ PENETRATION TESTING SCRAPER")
    print("=" * 60)
    print("Tento skript je určen pouze pro autorizované penetrační testování")
    print("anti-scrapingových mechanismů na základě smlouvy s firmou MERK.")
    print("=" * 60)
    
    scraper = MerkPentestScraper()
    scraper.run_scraping()

if __name__ == "__main__":
    main()